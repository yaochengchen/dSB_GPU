"""
å°†æ•´ä¸ªæ—¶é—´æ­¥å¾ªç¯éƒ½æ”¾å…¥ CUDA kernel çš„ç‰ˆæœ¬ - Cooperative Groupsä¼˜åŒ–ç‰ˆ
ä¸€æ¬¡ kernel è°ƒç”¨å®Œæˆæ‰€æœ‰ iterationsï¼Œæ”¯æŒçœŸæ­£çš„è·¨blockåŒæ­¥
"""

import torch
import time
from torch.utils.cpp_extension import load_inline

# â­ æ–°å¢ï¼šåŒ…å«Cooperative Groupsçš„CUDAæºä»£ç 
cuda_source_with_cooperative = '''
#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <cooperative_groups.h>  // â­ æ–°å¢ï¼šcooperative groupsæ”¯æŒ

using namespace cooperative_groups;  // â­ æ–°å¢

// â­ æ–°å¢ï¼šæ£€æŸ¥cooperative launchæ”¯æŒçš„è®¾å¤‡å‡½æ•°
__device__ bool is_cooperative_supported() {
    return true;  // åœ¨kernelå†…éƒ¨æ€»æ˜¯è¿”å›trueï¼Œå®é™…æ£€æŸ¥åœ¨hostç«¯
}

// ğŸ”„ ä¿®æ”¹ï¼šæ·»åŠ cooperative groupsæ”¯æŒçš„kernel
__global__ void __launch_bounds__(256, 4)  // â­ æ–°å¢ï¼šä¼˜åŒ–occupancy
fused_dynamics_cooperative_iterations_kernel(
    float* y,                   // è¾“å…¥è¾“å‡º: y æ•°ç»„ (N, batch_size)
    float* x,                   // è¾“å…¥è¾“å‡º: x æ•°ç»„ (N, batch_size)
    const float delta,          // æ ‡é‡å‚æ•°
    const float* p_array,       // p æ•°ç»„ (n_iterations,)
    const float xi,             // æ ‡é‡å‚æ•°
    const float dt,             // æ—¶é—´æ­¥é•¿
    const int* J_indices,       // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„åˆ—ç´¢å¼•
    const float* J_values,      // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„å€¼
    const int* J_crow_ptr,      // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„è¡ŒæŒ‡é’ˆ
    const int N,                // çŸ©é˜µç»´åº¦
    const int batch_size,       // batchå¤§å°
    const int n_iterations      // è¿­ä»£æ¬¡æ•°
) {
    // â­ æ–°å¢ï¼šåˆ›å»ºgrid-wide cooperative group
    grid_group grid = this_grid();
    
    // 2D grid: blockIdx.xå¯¹åº”Nç»´åº¦ï¼ŒblockIdx.yå¯¹åº”batchç»´åº¦
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    int batch = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (row >= N || batch >= batch_size) return;
    
    // è®¡ç®—åœ¨flattenæ•°ç»„ä¸­çš„ç´¢å¼•
    int idx = row * batch_size + batch;
    
    // è¯»å–åˆå§‹å€¼
    float x_val = x[idx];
    float y_val = y[idx];
    
    // â­ å…³é”®æ”¹åŠ¨ï¼šåœ¨kernelå†…éƒ¨æ‰§è¡Œæ‰€æœ‰æ—¶é—´æ­¥ + çœŸæ­£çš„å…¨å±€åŒæ­¥
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_array[iter];  // è·å–å½“å‰æ—¶é—´æ­¥çš„på€¼
        
        // Step 1: è®¡ç®—ç¨€ç–çŸ©é˜µä¹˜æ³• J * sign(x) çš„ç¬¬rowè¡Œ
        float sparse_result = 0.0f;
        int start = J_crow_ptr[row];
        int end = J_crow_ptr[row + 1];
        
        for (int j = start; j < end; j++) {
            int col_idx = J_indices[j];
            // ğŸ” è¿™é‡Œå¯èƒ½è¯»å–å…¶ä»–blockå¤„ç†çš„æ•°æ®
            float col_x = x[col_idx * batch_size + batch];
            
            // è®¡ç®— sign(col_x)
            float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
            sparse_result += J_values[j] * col_sign;
        }
        
        // Step 2: æ›´æ–° y
        float term1 = -(delta - p_i) * x_val;
        float term2 = xi * sparse_result;
        y_val += (term1 + term2) * dt;
        
        // Step 3: æ›´æ–° x
        x_val += dt * y_val * delta;
        
        // Step 4: æ¡ä»¶æˆªæ–­
        float abs_x = fabsf(x_val);
        if (abs_x > 1.0f) {
            x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
            y_val = 0.0f;
        }
        
        // â­ å…³é”®ï¼šå°†æ›´æ–°åçš„å€¼å†™å›å…¨å±€å†…å­˜ï¼Œä¾›å…¶ä»–çº¿ç¨‹è¯»å–
        x[idx] = x_val;
        y[idx] = y_val;
        
        // ğŸ”„ ä¿®æ”¹ï¼šæ›¿æ¢ __syncthreads() ä¸ºçœŸæ­£çš„è·¨blockåŒæ­¥
        grid.sync();  // â­ è¿™æ˜¯æ ¸å¿ƒæ”¹åŠ¨ï¼çœŸæ­£çš„å…¨å±€åŒæ­¥
    }
    
    // æœ€ç»ˆç»“æœå·²ç»å†™å…¥å…¨å±€å†…å­˜ï¼Œæ— éœ€é¢å¤–æ“ä½œ
}

// ğŸ”„ ä¿®æ”¹ï¼šä¿ç•™åŸç‰ˆæœ¬ä½œä¸ºfallback
__global__ void fused_dynamics_fallback_iterations_kernel(
    float* y, float* x, const float delta, const float* p_array,
    const float xi, const float dt, const int* J_indices,
    const float* J_values, const int* J_crow_ptr,
    const int N, const int batch_size, const int n_iterations
) {
    // åŸæ¥çš„å®ç°ï¼Œä½¿ç”¨ __syncthreads()
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    int batch = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (row >= N || batch >= batch_size) return;
    
    int idx = row * batch_size + batch;
    float x_val = x[idx];
    float y_val = y[idx];
    
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_array[iter];
        
        float sparse_result = 0.0f;
        int start = J_crow_ptr[row];
        int end = J_crow_ptr[row + 1];
        
        for (int j = start; j < end; j++) {
            int col_idx = J_indices[j];
            float col_x = x[col_idx * batch_size + batch];
            float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
            sparse_result += J_values[j] * col_sign;
        }
        
        float term1 = -(delta - p_i) * x_val;
        float term2 = xi * sparse_result;
        y_val += (term1 + term2) * dt;
        x_val += dt * y_val * delta;
        
        if (fabsf(x_val) > 1.0f) {
            x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
            y_val = 0.0f;
        }
        
        x[idx] = x_val;
        y[idx] = y_val;
        
        __syncthreads();  // åŸæ¥çš„blockå†…åŒæ­¥
    }
}

// â­ æ–°å¢ï¼šæ£€æŸ¥cooperative launchæ”¯æŒ
bool check_cooperative_launch_support() {
    int device;
    cudaGetDevice(&device);
    
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, device);
    
    // æ£€æŸ¥ç¡¬ä»¶æ”¯æŒ (CC 6.0+)
    if (prop.major < 6) {
        return false;
    }
    
    // æ£€æŸ¥é©±åŠ¨æ”¯æŒ
    int cooperative_launch = 0;
    cudaDeviceGetAttribute(&cooperative_launch, 
                          cudaDevAttrCooperativeLaunch, device);
    
    return cooperative_launch != 0;
}

// â­ ä¿®æ­£ï¼šcooperative launchå®ç°ï¼Œç§»åˆ°CUDAæºç ä¸­
bool launch_cooperative_kernel_wrapper(
    float* y, float* x, float delta, float* p_array,
    float xi, float dt, int* J_indices, float* J_values, int* J_crow_ptr,
    int N, int batch_size, int n_iterations,
    int blocks_x, int blocks_y, int threads_x, int threads_y  // â­ ä¿®æ­£ï¼šä½¿ç”¨intå‚æ•°
) {
    // 1. è½¬æ¢ä¸ºdim3ç±»å‹
    dim3 blocks(blocks_x, blocks_y);
    dim3 threads(threads_x, threads_y);
    
    // 2. æ£€æŸ¥grid sizeé™åˆ¶
    int device;
    cudaGetDevice(&device);
    
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, device);
    
    int max_blocks_per_sm;
    cudaOccupancyMaxActiveBlocksPerMultiprocessor(
        &max_blocks_per_sm,
        fused_dynamics_cooperative_iterations_kernel,
        threads.x * threads.y, 0
    );
    
    int max_blocks = max_blocks_per_sm * prop.multiProcessorCount;
    int requested_blocks = blocks.x * blocks.y;
    
    if (requested_blocks > max_blocks) {
        printf("è­¦å‘Šï¼šè¯·æ±‚%dä¸ªblockï¼Œä½†æœ€å¤§æ”¯æŒ%dä¸ª\\n", 
               requested_blocks, max_blocks);
        return false;  // â­ ä¿®æ­£ï¼šè¿”å›boolè€Œä¸æ˜¯cudaError_t
    }
    
    // 3. è®¾ç½®launchå‚æ•°
    void* args[] = {
        &y, &x, &delta, &p_array, &xi, &dt,
        &J_indices, &J_values, &J_crow_ptr,
        &N, &batch_size, &n_iterations
    };
    
    // â­ 4. ä½¿ç”¨cooperative launch
    cudaError_t result = cudaLaunchCooperativeKernel(
        (void*)fused_dynamics_cooperative_iterations_kernel,
        blocks,                    // grid size
        threads,                   // block size
        args,                      // kernel arguments
        0,                         // shared memory
        0                          // stream
    );
    
    return result == cudaSuccess;  // â­ ä¿®æ­£ï¼šè¿”å›bool
}

// ğŸ”„ ä¿®æ”¹ï¼šwrapperå‡½æ•°æ”¯æŒcooperativeå’Œfallback
void fused_dynamics_batch_iterations_cuda_wrapper(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    const int N = x.size(0);
    const int batch_size = x.size(1);
    
    // 2D gridè®¾ç½®
    const int threads_x = 16;
    const int threads_y = 16;
    
    dim3 threads(threads_x, threads_y);
    dim3 blocks(
        (N + threads_x - 1) / threads_x,
        (batch_size + threads_y - 1) / threads_y
    );
    
    // â­ æ–°å¢ï¼šæ£€æŸ¥cooperative launchæ”¯æŒå¹¶é€‰æ‹©åˆé€‚çš„kernel
    static bool coop_supported = check_cooperative_launch_support();
    static bool coop_check_done = false;
    
    if (!coop_check_done) {
        if (coop_supported) {
            printf("âœ… ä½¿ç”¨Cooperative Groupsä¼˜åŒ–ç‰ˆæœ¬\\n");
        } else {
            printf("âš ï¸ GPUä¸æ”¯æŒCooperative Launchï¼Œä½¿ç”¨fallbackç‰ˆæœ¬\\n");
        }
        coop_check_done = true;
    }
    
    if (coop_supported) {
        // â­ å°è¯•ä½¿ç”¨cooperative launch
        bool success = launch_cooperative_kernel_wrapper(
            y.data_ptr<float>(), x.data_ptr<float>(),
            delta, p_array.data_ptr<float>(), xi, dt,
            J_indices.data_ptr<int>(), J_values.data_ptr<float>(),
            J_crow_ptr.data_ptr<int>(),
            N, batch_size, n_iterations, 
            blocks.x, blocks.y, threads.x, threads.y  // â­ ä¿®æ­£ï¼šä¼ é€’intå‚æ•°
        );
        
        if (success) {
            cudaDeviceSynchronize();
            return;
        } else {
            printf("âŒ Cooperative launchå¤±è´¥ï¼Œä½¿ç”¨fallback...\\n");
            // ç»§ç»­æ‰§è¡Œfallbackç‰ˆæœ¬
        }
    }
    
    // ğŸ”„ Fallbackï¼šä½¿ç”¨åŸæ¥çš„kernelï¼ˆblockå†…åŒæ­¥ï¼‰
    fused_dynamics_fallback_iterations_kernel<<<blocks, threads>>>(
        y.data_ptr<float>(),
        x.data_ptr<float>(),
        delta,
        p_array.data_ptr<float>(),
        xi, dt,
        J_indices.data_ptr<int>(),
        J_values.data_ptr<float>(),
        J_crow_ptr.data_ptr<int>(),
        N, batch_size, n_iterations
    );
    
    cudaDeviceSynchronize();
}
'''

# ğŸ”„ ä¿®æ”¹ï¼šC++ç»‘å®šä»£ç ï¼Œä¿®æ­£CUDAç±»å‹é—®é¢˜
cpp_source_cooperative = '''
#include <torch/extension.h>

// â­ ä¿®æ­£ï¼šåªå£°æ˜ä¸æ¶‰åŠCUDAç±»å‹çš„å‡½æ•°
bool check_cooperative_launch_support();
bool launch_cooperative_kernel_wrapper(
    float* y, float* x, float delta, float* p_array,
    float xi, float dt, int* J_indices, float* J_values, int* J_crow_ptr,
    int N, int batch_size, int n_iterations,
    int blocks_x, int blocks_y, int threads_x, int threads_y  // â­ ä¿®æ­£ï¼šä½¿ç”¨intè€Œä¸æ˜¯dim3
);

void fused_dynamics_batch_iterations_cuda_wrapper(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
);

void fused_dynamics_batch_iterations_cpu(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    auto y_acc = y.accessor<float, 2>();
    auto x_acc = x.accessor<float, 2>();
    auto p_acc = p_array.accessor<float, 1>();
    auto J_indices_acc = J_indices.accessor<int, 1>();
    auto J_values_acc = J_values.accessor<float, 1>();
    auto J_crow_ptr_acc = J_crow_ptr.accessor<int, 1>();
    
    int N = x.size(0);
    int batch_size = x.size(1);
    
    // â­ CPUç‰ˆæœ¬ï¼šå¤–å±‚æ˜¯iterationå¾ªç¯
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_acc[iter];
        
        // ä¸ºå½“å‰iterationåˆ›å»ºä¸´æ—¶æ•°ç»„å­˜å‚¨æ›´æ–°å€¼
        auto y_temp = torch::zeros_like(y);
        auto x_temp = torch::zeros_like(x);
        auto y_temp_acc = y_temp.accessor<float, 2>();
        auto x_temp_acc = x_temp.accessor<float, 2>();
        
        #pragma omp parallel for collapse(2)
        for (int row = 0; row < N; row++) {
            for (int batch = 0; batch < batch_size; batch++) {
                float x_val = x_acc[row][batch];
                float y_val = y_acc[row][batch];
                
                // è®¡ç®—ç¨€ç–çŸ©é˜µä¹˜æ³•
                float sparse_result = 0.0f;
                int start = J_crow_ptr_acc[row];
                int end = J_crow_ptr_acc[row + 1];
                
                for (int j = start; j < end; j++) {
                    int col_idx = J_indices_acc[j];
                    float col_x = x_acc[col_idx][batch];
                    float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
                    sparse_result += J_values_acc[j] * col_sign;
                }
                
                // æ›´æ–° y
                float term1 = -(delta - p_i) * x_val;
                float term2 = xi * sparse_result;
                y_val += (term1 + term2) * dt;
                
                // æ›´æ–° x
                x_val += dt * y_val * delta;
                
                // æ¡ä»¶æˆªæ–­
                if (std::abs(x_val) > 1.0f) {
                    x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
                    y_val = 0.0f;
                }
                
                y_temp_acc[row][batch] = y_val;
                x_temp_acc[row][batch] = x_val;
            }
        }
        
        // æ‹·è´ä¸´æ—¶ç»“æœå›åŸæ•°ç»„
        y.copy_(y_temp);
        x.copy_(x_temp);
    }
}

// â­ æ–°å¢ï¼šæ£€æŸ¥è®¾å¤‡èƒ½åŠ›çš„å‡½æ•°
bool check_device_cooperative_support() {
    return check_cooperative_launch_support();
}

void fused_dynamics_batch_iterations(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    if (y.is_cuda()) {
        fused_dynamics_batch_iterations_cuda_wrapper(
            y, x, delta, p_array, xi, dt, 
            J_indices, J_values, J_crow_ptr, n_iterations
        );
    } else {
        fused_dynamics_batch_iterations_cpu(
            y, x, delta, p_array, xi, dt, 
            J_indices, J_values, J_crow_ptr, n_iterations
        );
    }
}

// â­ æ–°å¢ï¼šæš´éœ²è®¾å¤‡æ£€æŸ¥å‡½æ•°åˆ°Python
PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.def("fused_dynamics_batch_iterations", &fused_dynamics_batch_iterations, 
          "Fused dynamics with cooperative groups support");
    m.def("check_device_cooperative_support", &check_device_cooperative_support,
          "Check if device supports cooperative launch");
}
'''

class BatchIterationCooperativeFusedJIT:
    """â­ æ–°å¢ï¼šæ”¯æŒCooperative Groupsçš„ç‰ˆæœ¬"""
    
    _module = None
    _compilation_attempted = False
    _cooperative_supported = None  # â­ æ–°å¢ï¼šç¼“å­˜cooperativeæ”¯æŒçŠ¶æ€
    
    def __init__(self, J, use_cuda=True, verbose=False):
        self.use_cuda = use_cuda and torch.cuda.is_available()
        self.verbose = verbose
        
        # é¢„å¤„ç†ç¨€ç–çŸ©é˜µ
        if hasattr(J, 'to_sparse_csr'):
            self.J_csr = J.to_sparse_csr()
        else:
            self.J_csr = J.coalesce()
        
        # ç¼–è¯‘CUDAæ‰©å±•
        if self.use_cuda:
            self._compile_cuda_extension()
        
        # PyTorchå›é€€ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
        self.torch_update = self._single_step_update
        
    
    def _compile_cuda_extension(self):
        if BatchIterationCooperativeFusedJIT._compilation_attempted:
            return
        
        BatchIterationCooperativeFusedJIT._compilation_attempted = True
        
        try:
            if self.verbose:
                print("æ­£åœ¨ç¼–è¯‘åŒ…å«Cooperative Groupsçš„CUDAæ‰©å±•...")
            
            BatchIterationCooperativeFusedJIT._module = load_inline(
                name='cooperative_fused_dynamics_jit',  # ğŸ”„ ä¿®æ”¹ï¼šæ›´æ–°åç§°
                cpp_sources=[cpp_source_cooperative],  # ğŸ”„ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„C++æºç 
                cuda_sources=[cuda_source_with_cooperative] if self.use_cuda else [],  # ğŸ”„ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„CUDAæºç 
                functions=['fused_dynamics_batch_iterations', 'check_device_cooperative_support'],  # â­ æ–°å¢ï¼šæ·»åŠ æ£€æŸ¥å‡½æ•°
                extra_cflags=['-O3', '-std=c++17', '-fopenmp'],
                extra_cuda_cflags=[
                    '-O3', '--std=c++17',
                    '-gencode=arch=compute_70,code=sm_70',  # â­ ç¡®ä¿CC 6.0+æ”¯æŒ
                    '-gencode=arch=compute_75,code=sm_75',
                    '-gencode=arch=compute_80,code=sm_80',
                    '-gencode=arch=compute_86,code=sm_86',
                    '--use_fast_math',
                    '--extended-lambda'  # â­ æ–°å¢ï¼šæ”¯æŒcooperative groups
                ] if self.use_cuda else [],
                verbose=self.verbose
            )
            
            if self.verbose:
                print("âœ… Cooperative Groups CUDAæ‰©å±•ç¼–è¯‘å®Œæˆï¼")
                
            # â­ æ–°å¢ï¼šæ£€æŸ¥cooperativeæ”¯æŒ
            if BatchIterationCooperativeFusedJIT._module is not None:
                try:
                    BatchIterationCooperativeFusedJIT._cooperative_supported = \
                        BatchIterationCooperativeFusedJIT._module.check_device_cooperative_support()
                    if self.verbose:
                        if BatchIterationCooperativeFusedJIT._cooperative_supported:
                            print("âœ… è®¾å¤‡æ”¯æŒCooperative Launch")
                        else:
                            print("âš ï¸ è®¾å¤‡ä¸æ”¯æŒCooperative Launchï¼Œå°†ä½¿ç”¨fallback")
                except:
                    BatchIterationCooperativeFusedJIT._cooperative_supported = False
                    if self.verbose:
                        print("âš ï¸ æ— æ³•æ£€æµ‹Cooperative Launchæ”¯æŒï¼Œå‡è®¾ä¸æ”¯æŒ")
                
        except Exception as e:
            if self.verbose:
                print(f"âŒ CUDAç¼–è¯‘å¤±è´¥ï¼Œä½¿ç”¨PyTorchå›é€€: {e}")
            BatchIterationCooperativeFusedJIT._module = None
    
    # â­ æ–°å¢ï¼šæ£€æŸ¥cooperativeæ”¯æŒçŠ¶æ€
    def is_cooperative_supported(self):
        """æ£€æŸ¥å½“å‰è®¾å¤‡æ˜¯å¦æ”¯æŒcooperative launch"""
        if BatchIterationCooperativeFusedJIT._cooperative_supported is None:
            return False
        return BatchIterationCooperativeFusedJIT._cooperative_supported
    
    # ğŸ”„ ä¿®æ”¹ï¼šå‡½æ•°ç­¾åä¿®æ­£ï¼Œæ·»åŠ n_iterationså‚æ•°
    def run_iterations(self, y, x, delta, p_array, xi, dt, n_iterations):
        """
        è¿è¡Œå¤šä¸ªæ—¶é—´æ­¥
        
        Args:
            y, x: (N, batch_size) çŠ¶æ€å¼ é‡
            delta, xi, dt: æ ‡é‡å‚æ•°
            p_array: (n_iterations,) å‚æ•°æ•°ç»„
            n_iterations: è¿­ä»£æ¬¡æ•°  # â­ æ–°å¢ï¼šæ˜ç¡®çš„è¿­ä»£æ¬¡æ•°å‚æ•°
            
        Returns:
            y, x: æ›´æ–°åçš„çŠ¶æ€å¼ é‡
        """
        
        if BatchIterationCooperativeFusedJIT._module is not None and y.is_cuda:
            return self._cuda_iterations(y, x, delta, p_array, xi, dt, n_iterations)
        else:
            return self._torch_iterations(y, x, delta, p_array, xi, dt)
    
    def _cuda_iterations(self, y, x, delta, p_array, xi, dt, n_iterations):
        """â­ CUDAç‰ˆæœ¬ï¼šæ”¯æŒcooperative groupsçš„ä¸€æ¬¡kernelè°ƒç”¨"""
        # ç¡®ä¿æ•°æ®ç±»å‹å’Œè¿ç»­æ€§
        if y.dtype != torch.float32:
            y = y.float()
        if x.dtype != torch.float32:
            x = x.float()
        if p_array.dtype != torch.float32:
            p_array = p_array.float()
        
        if not y.is_contiguous():
            y = y.contiguous()
        if not x.is_contiguous():
            x = x.contiguous()
        if not p_array.is_contiguous():
            p_array = p_array.contiguous()
        
        # è·å–CSRæ ¼å¼æ•°æ®
        if hasattr(self.J_csr, 'crow_indices'):
            crow_indices = self.J_csr.crow_indices().int().contiguous()
            col_indices = self.J_csr.col_indices().int().contiguous()
            values = self.J_csr.values().float().contiguous()
        else:
            raise NotImplementedError("è¯·ä½¿ç”¨PyTorch 1.13+")
        
        # ç¡®ä¿æ•°æ®åœ¨GPUä¸Š
        if not crow_indices.is_cuda:
            crow_indices = crow_indices.cuda()
        if not col_indices.is_cuda:
            col_indices = col_indices.cuda()
        if not values.is_cuda:
            values = values.cuda()
        if not p_array.is_cuda:
            p_array = p_array.cuda()
        
        # â­ ä¸€æ¬¡kernelè°ƒç”¨å®Œæˆæ‰€æœ‰iterationsï¼ˆæ”¯æŒcooperative groupsï¼‰
        BatchIterationCooperativeFusedJIT._module.fused_dynamics_batch_iterations(
            y, x, float(delta), p_array, float(xi), float(dt),
            col_indices, values, crow_indices, n_iterations
        )
        
        return y, x
    
    def _torch_iterations(self, y, x, delta, p_array, xi, dt):
        """ä¼ ç»ŸPyTorchç‰ˆæœ¬ï¼šå¾ªç¯è°ƒç”¨å•æ­¥æ›´æ–°"""
        for i in range(len(p_array)):
            y, x = self.torch_update(y, x, delta, p_array[i].item(), xi, dt)
        return y, x
    
    def _single_step_update(self, y, x, delta, p_i, xi, dt):
        """å•æ­¥æ›´æ–°çš„PyTorchå®ç°"""
        sign_x = torch.sign(x)
        sparse_term = torch.sparse.mm(self.J_csr, sign_x)
        y = y + (-(delta - p_i) * x + xi * sparse_term) * dt
        x = x + dt * y * delta
        
        cond = torch.abs(x) > 1
        x = torch.where(cond, torch.sign(x), x)
        y = torch.where(cond, torch.zeros_like(x), y)
        
        return y, x

# â­ æ–°å¢ï¼šå…¼å®¹æ€§ç±»ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰ˆæœ¬
class BatchIterationFusedJIT(BatchIterationCooperativeFusedJIT):
    """å…¼å®¹æ€§wrapperï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³å®ç°"""
    def __init__(self, J, use_cuda=True, verbose=False):
        super().__init__(J, use_cuda, verbose)
        if verbose and self.use_cuda:
            if self.is_cooperative_supported():
                print("ğŸš€ ä½¿ç”¨Cooperative Groupsä¼˜åŒ–ç‰ˆæœ¬")
            else:
                print("ğŸ“¦ ä½¿ç”¨ä¼ ç»Ÿç‰ˆæœ¬ï¼ˆblockå†…åŒæ­¥ï¼‰")

def demo_cooperative_iteration_fusion():
    """â­ æ–°å¢ï¼šæ¼”ç¤ºcooperative groupsçš„æ€§èƒ½æå‡"""
    print("=== Cooperative Groups Iterationèåˆæ€§èƒ½å¯¹æ¯” ===")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    N = 200
    batch_size = 1000
    n_iterations = 1000
    
    print(f"è®¾å¤‡: {device}")
    print(f"çŸ©é˜µå¤§å°: {N}x{N}")
    print(f"Batchå¤§å°: {batch_size}")
    print(f"è¿­ä»£æ¬¡æ•°: {n_iterations}")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    nnz = N * 8
    indices = torch.randint(0, N, (2, nnz), device=device)
    values = torch.randn(nnz, device=device) * 0.1
    J = torch.sparse_coo_tensor(indices, values, (N, N), device=device)
    
    y = torch.randn(N, batch_size, device=device)
    x = torch.randn(N, batch_size, device=device)
    
    delta, xi, dt = 0.1, 0.5, 0.01
    p_array = torch.randn(n_iterations, device=device)
    
    # â­ æ–¹æ³•1: Cooperative Groupsç‰ˆæœ¬
    print("\n--- æ–¹æ³•1: Cooperative Groupsç‰ˆæœ¬ ---")
    cooperative_updater = BatchIterationCooperativeFusedJIT(J, use_cuda=True, verbose=True)
    y1, x1 = y.clone(), x.clone()
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        start.record()
        
        y1, x1 = cooperative_updater.run_iterations(y1, x1, delta, p_array, xi, dt, n_iterations)
        
        end.record()
        torch.cuda.synchronize()
        cooperative_time = start.elapsed_time(end)
    else:
        start_time = time.time()
        y1, x1 = cooperative_updater.run_iterations(y1, x1, delta, p_array, xi, dt, n_iterations)
        cooperative_time = (time.time() - start_time) * 1000
    
    print(f"Cooperative Groupsè€—æ—¶: {cooperative_time:.2f}ms")
    
    # æ–¹æ³•2: ä¼ ç»Ÿæ–¹å¼ï¼ˆå¤šæ¬¡kernelè°ƒç”¨ï¼‰
    print("\n--- æ–¹æ³•2: ä¼ ç»Ÿæ–¹å¼ï¼ˆå¤šæ¬¡kernelè°ƒç”¨ï¼‰---")
    from batch_fused_dynamics import create_batch_fused_update
    
    traditional_updater = create_batch_fused_update(J, simple_mode=True, verbose=False)
    y2, x2 = y.clone(), x.clone()
    
    if torch.cuda.is_available():
        start.record()
        
        for i in range(n_iterations):
            y2, x2 = traditional_updater(y2, x2, delta, p_array[i].item(), xi, dt)
        
        end.record()
        torch.cuda.synchronize()
        traditional_time = start.elapsed_time(end)
    else:
        start_time = time.time()
        for i in range(n_iterations):
            y2, x2 = traditional_updater(y2, x2, delta, p_array[i].item(), xi, dt)
        traditional_time = (time.time() - start_time) * 1000
    
    print(f"ä¼ ç»Ÿæ–¹å¼è€—æ—¶: {traditional_time:.2f}ms")
    
    # æ€§èƒ½å¯¹æ¯”
    if cooperative_time > 0:
        speedup = traditional_time / cooperative_time
        print(f"\nğŸš€ Cooperative GroupsåŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"èŠ‚çœæ—¶é—´: {traditional_time - cooperative_time:.2f}ms ({(1-cooperative_time/traditional_time)*100:.1f}%)")
        
        # â­ æ–°å¢ï¼šæ˜¾ç¤ºåŒæ­¥æ–¹å¼ä¿¡æ¯
        if cooperative_updater.is_cooperative_supported():
            print("âœ… ä½¿ç”¨äº†çœŸæ­£çš„è·¨blockåŒæ­¥ (grid.sync())")
        else:
            print("âš ï¸ ä½¿ç”¨äº†blockå†…åŒæ­¥ (__syncthreads())")
    
    # éªŒè¯æ•°å€¼ä¸€è‡´æ€§
    y_diff = torch.max(torch.abs(y1 - y2)).item()
    x_diff = torch.max(torch.abs(x1 - x2)).item()
    print(f"\næ•°å€¼å·®å¼‚: y={y_diff:.2e}, x={x_diff:.2e}")
    
    if y_diff < 1e-4 and x_diff < 1e-4:
        print("âœ… æ•°å€¼éªŒè¯é€šè¿‡!")
    else:
        print("âš ï¸  æ•°å€¼æœ‰è½»å¾®å·®å¼‚ï¼ˆåœ¨GPUå¹¶è¡Œè®¡ç®—ä¸­æ˜¯æ­£å¸¸çš„ï¼‰")
    
    return speedup if cooperative_time > 0 else 0

# ğŸ”„ ä¿®æ”¹ï¼šä¿æŒåŸæœ‰æ¥å£å…¼å®¹æ€§
def demo_iteration_fusion():
    """åŸæœ‰çš„demoå‡½æ•°ï¼Œç°åœ¨è°ƒç”¨cooperativeç‰ˆæœ¬"""
    return demo_cooperative_iteration_fusion()

if __name__ == "__main__":
    demo_cooperative_iteration_fusion()  # â­ æ–°å¢ï¼šè¿è¡Œcooperativeç‰ˆæœ¬çš„demo
