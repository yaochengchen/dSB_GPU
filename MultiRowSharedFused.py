"""
æ”¯æŒN>1024çš„å…±äº«å†…å­˜ç‰ˆæœ¬ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrow
"""

import torch
import time
from torch.utils.cpp_extension import load_inline

# â­ æ”¯æŒå¤§Nçš„CUDAæºä»£ç ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrow
cuda_source_multi_row_shared = '''
#include <cuda_runtime.h>
#include <device_launch_parameters.h>

// â­ æ”¯æŒå¤§Nï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrowçš„å…±äº«å†…å­˜ç‰ˆæœ¬
__global__ void __launch_bounds__(1024, 2)
fused_dynamics_xy_shared_multi_row_kernel(
    float* y,                   // è¾“å…¥è¾“å‡º: y æ•°ç»„ (N, batch_size)
    float* x,                   // è¾“å…¥è¾“å‡º: x æ•°ç»„ (N, batch_size)  
    const float delta,          // æ ‡é‡å‚æ•°
    const float* p_array,       // p æ•°ç»„ (n_iterations,)
    const float xi,             // æ ‡é‡å‚æ•°
    const float dt,             // æ—¶é—´æ­¥é•¿
    const int* J_indices,       // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„åˆ—ç´¢å¼•
    const float* J_values,      // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„å€¼
    const int* J_crow_ptr,      // CSRæ ¼å¼ç¨€ç–çŸ©é˜µçš„è¡ŒæŒ‡é’ˆ
    const int N,                // çŸ©é˜µç»´åº¦
    const int batch_size,       // batchå¤§å°
    const int n_iterations      // è¿­ä»£æ¬¡æ•°
) {
    // æ¯ä¸ªblockå¤„ç†ä¸€ä¸ªbatch
    int batch = blockIdx.y;
    int thread_id = threadIdx.x;
    
    if (batch >= batch_size) return;
    
    // â­ å…±äº«å†…å­˜ï¼šå­˜å‚¨å®Œæ•´çš„xå’Œyå‘é‡
    extern __shared__ float shared_data[];
    float* shared_x = shared_data;           // Nä¸ªfloat
    float* shared_y = shared_data + N;       // Nä¸ªfloat
    
    // â­ æ¯ä¸ªçº¿ç¨‹è´Ÿè´£çš„rowæ•°é‡
    int rows_per_thread = (N + blockDim.x - 1) / blockDim.x;
    
    // â­ åŠ è½½æ•°æ®åˆ°å…±äº«å†…å­˜ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrow
    for (int i = 0; i < rows_per_thread; i++) {
        int row = thread_id + i * blockDim.x;
        if (row < N) {
            int global_idx = row * batch_size + batch;
            shared_x[row] = x[global_idx];
            shared_y[row] = y[global_idx];
        }
    }
    __syncthreads();
    
    // â­ è¿­ä»£è®¡ç®—
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_array[iter];
        
        // â­ æ¯ä¸ªçº¿ç¨‹å¤„ç†å®ƒè´Ÿè´£çš„æ‰€æœ‰row
        for (int i = 0; i < rows_per_thread; i++) {
            int row = thread_id + i * blockDim.x;
            if (row < N) {
                float x_val = shared_x[row];
                float y_val = shared_y[row];
                
                // ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼šä»å…±äº«å†…å­˜è¯»å–xæ•°æ®
                float sparse_result = 0.0f;
                int start = J_crow_ptr[row];
                int end = J_crow_ptr[row + 1];
                
                for (int j = start; j < end; j++) {
                    int col_idx = J_indices[j];
                    float j_value = J_values[j];
                    
                    if (col_idx < N) {
                        float col_x = shared_x[col_idx];  // ä»å…±äº«å†…å­˜è¯»å–
                        float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
                        sparse_result += j_value * col_sign;
                    }
                }
                
                // æ›´æ–°è®¡ç®—
                float term1 = -(delta - p_i) * x_val;
                float term2 = xi * sparse_result;
                y_val += (term1 + term2) * dt;
                x_val += dt * y_val * delta;
                
                // æ¡ä»¶æˆªæ–­
                if (fabsf(x_val) > 1.0f) {
                    x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
                    y_val = 0.0f;
                }
                
                // æ›´æ–°å…±äº«å†…å­˜ä¸­çš„å€¼
                shared_x[row] = x_val;
                shared_y[row] = y_val;
            }
        }
        
        __syncthreads();  // ç¡®ä¿æ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆäº†è¿™ä¸€è½®è¿­ä»£
    }
    
    // â­ å†™å›å…¨å±€å†…å­˜ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrow
    for (int i = 0; i < rows_per_thread; i++) {
        int row = thread_id + i * blockDim.x;
        if (row < N) {
            int global_idx = row * batch_size + batch;
            x[global_idx] = shared_x[row];
            y[global_idx] = shared_y[row];
        }
    }
}

// ğŸ”„ ä¿ç•™åŸæ¥çš„fallback kernel
__global__ void fused_dynamics_fallback_iterations_kernel(
    float* y, float* x, const float delta, const float* p_array,
    float xi, float dt, const int* J_indices,
    const float* J_values, const int* J_crow_ptr,
    const int N, const int batch_size, const int n_iterations
) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;
    int batch = blockIdx.y * blockDim.y + threadIdx.y;
    
    if (row >= N || batch >= batch_size) return;
    
    int idx = row * batch_size + batch;
    float x_val = x[idx];
    float y_val = y[idx];
    
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_array[iter];
        
        float sparse_result = 0.0f;
        int start = J_crow_ptr[row];
        int end = J_crow_ptr[row + 1];
        
        for (int j = start; j < end; j++) {
            int col_idx = J_indices[j];
            float col_x = x[col_idx * batch_size + batch];
            float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
            sparse_result += J_values[j] * col_sign;
        }
        
        float term1 = -(delta - p_i) * x_val;
        float term2 = xi * sparse_result;
        y_val += (term1 + term2) * dt;
        x_val += dt * y_val * delta;
        
        if (fabsf(x_val) > 1.0f) {
            x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
            y_val = 0.0f;
        }
        
        x[idx] = x_val;
        y[idx] = y_val;
        
        __syncthreads();
    }
}

// â­ æ£€æŸ¥å¤šè¡Œå…±äº«å†…å­˜æ”¯æŒï¼ˆæ”¯æŒä»»æ„å¤§çš„Nï¼‰
bool check_multi_row_shared_memory_support(int N, int* max_threads_per_block) {
    int device;
    cudaGetDevice(&device);
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, device);
    
    size_t shared_mem_needed = 2 * N * sizeof(float);  // xå’Œy
    *max_threads_per_block = prop.maxThreadsPerBlock;  // é€šå¸¸æ˜¯1024
    
    return shared_mem_needed <= prop.sharedMemPerBlock;
}

// â­ å¯åŠ¨å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬
bool launch_multi_row_shared_kernel_wrapper(
    float* y, float* x, float delta, float* p_array,
    float xi, float dt, int* J_indices, float* J_values, int* J_crow_ptr,
    int N, int batch_size, int n_iterations
) {
    // æ£€æŸ¥å…±äº«å†…å­˜éœ€æ±‚
    int max_threads_per_block;
    if (!check_multi_row_shared_memory_support(N, &max_threads_per_block)) {
        return false;
    }
    
    size_t shared_mem_needed = 2 * N * sizeof(float);
    
    printf("âœ… å¤šè¡Œå…±äº«å†…å­˜ä½¿ç”¨: %zuå­—èŠ‚, N=%d\\n", shared_mem_needed, N);
    printf("   æ¯ä¸ªçº¿ç¨‹å¤„ç† %.1f ä¸ªrow\\n", (float)N / max_threads_per_block);
    
    // â­ å¯åŠ¨é…ç½®ï¼šæ¯ä¸ªbatchä¸€ä¸ªblockï¼Œä½¿ç”¨æœ€å¤§çº¿ç¨‹æ•°
    dim3 blocks(1, batch_size);
    dim3 threads(max_threads_per_block, 1);  // ä½¿ç”¨æœ€å¤§çº¿ç¨‹æ•°(é€šå¸¸1024)
    
    fused_dynamics_xy_shared_multi_row_kernel<<<blocks, threads, shared_mem_needed>>>(
        y, x, delta, p_array, xi, dt,
        J_indices, J_values, J_crow_ptr,
        N, batch_size, n_iterations
    );
    
    cudaError_t result = cudaGetLastError();
    return result == cudaSuccess;
}

// ğŸ”„ ä¿®æ”¹wrapperå‡½æ•°ï¼Œä¼˜å…ˆä½¿ç”¨å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬
void fused_dynamics_batch_iterations_cuda_wrapper(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    const int N = x.size(0);
    const int batch_size = x.size(1);
    
    // â­ æ£€æŸ¥å¤šè¡Œå…±äº«å†…å­˜æ”¯æŒ
    int max_threads_per_block;
    static bool multi_row_shared_supported = check_multi_row_shared_memory_support(N, &max_threads_per_block);
    static bool support_check_done = false;
    
    if (!support_check_done) {
        if (multi_row_shared_supported) {
            printf("âœ… ä½¿ç”¨å¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ (æ”¯æŒN>1024)\\n");
        } else {
            printf("âš ï¸ ä¸æ”¯æŒå¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–ï¼Œä½¿ç”¨ä¼ ç»Ÿç‰ˆæœ¬\\n");
        }
        support_check_done = true;
    }
    
    if (multi_row_shared_supported) {
        // â­ ä½¿ç”¨å¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
        bool success = launch_multi_row_shared_kernel_wrapper(
            y.data_ptr<float>(), x.data_ptr<float>(),
            delta, p_array.data_ptr<float>(), xi, dt,
            J_indices.data_ptr<int>(), J_values.data_ptr<float>(),
            J_crow_ptr.data_ptr<int>(),
            N, batch_size, n_iterations
        );
        
        if (success) {
            cudaDeviceSynchronize();
            return;
        } else {
            printf("âŒ å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬å¯åŠ¨å¤±è´¥ï¼Œä½¿ç”¨fallback...\\n");
        }
    }
    
    // ğŸ”„ Fallbackï¼šä½¿ç”¨ä¼ ç»Ÿçš„2D gridé…ç½®
    const int threads_x = 16;
    const int threads_y = 16;
    
    dim3 threads(threads_x, threads_y);
    dim3 blocks(
        (N + threads_x - 1) / threads_x,
        (batch_size + threads_y - 1) / threads_y
    );
    
    fused_dynamics_fallback_iterations_kernel<<<blocks, threads>>>(
        y.data_ptr<float>(),
        x.data_ptr<float>(),
        delta,
        p_array.data_ptr<float>(),
        xi, dt,
        J_indices.data_ptr<int>(),
        J_values.data_ptr<float>(),
        J_crow_ptr.data_ptr<int>(),
        N, batch_size, n_iterations
    );
    
    cudaDeviceSynchronize();
}
'''

# ğŸ”„ C++ç»‘å®šä»£ç 
cpp_source_multi_row = '''
#include <torch/extension.h>

bool check_multi_row_shared_memory_support(int N, int* max_threads_per_block);
bool launch_multi_row_shared_kernel_wrapper(
    float* y, float* x, float delta, float* p_array,
    float xi, float dt, int* J_indices, float* J_values, int* J_crow_ptr,
    int N, int batch_size, int n_iterations
);

void fused_dynamics_batch_iterations_cuda_wrapper(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
);

void fused_dynamics_batch_iterations_cpu(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    auto y_acc = y.accessor<float, 2>();
    auto x_acc = x.accessor<float, 2>();
    auto p_acc = p_array.accessor<float, 1>();
    auto J_indices_acc = J_indices.accessor<int, 1>();
    auto J_values_acc = J_values.accessor<float, 1>();
    auto J_crow_ptr_acc = J_crow_ptr.accessor<int, 1>();
    
    int N = x.size(0);
    int batch_size = x.size(1);
    
    for (int iter = 0; iter < n_iterations; iter++) {
        float p_i = p_acc[iter];
        
        auto y_temp = torch::zeros_like(y);
        auto x_temp = torch::zeros_like(x);
        auto y_temp_acc = y_temp.accessor<float, 2>();
        auto x_temp_acc = x_temp.accessor<float, 2>();
        
        #pragma omp parallel for collapse(2)
        for (int row = 0; row < N; row++) {
            for (int batch = 0; batch < batch_size; batch++) {
                float x_val = x_acc[row][batch];
                float y_val = y_acc[row][batch];
                
                float sparse_result = 0.0f;
                int start = J_crow_ptr_acc[row];
                int end = J_crow_ptr_acc[row + 1];
                
                for (int j = start; j < end; j++) {
                    int col_idx = J_indices_acc[j];
                    float col_x = x_acc[col_idx][batch];
                    float col_sign = (col_x > 0.0f) ? 1.0f : ((col_x < 0.0f) ? -1.0f : 0.0f);
                    sparse_result += J_values_acc[j] * col_sign;
                }
                
                float term1 = -(delta - p_i) * x_val;
                float term2 = xi * sparse_result;
                y_val += (term1 + term2) * dt;
                x_val += dt * y_val * delta;
                
                if (std::abs(x_val) > 1.0f) {
                    x_val = (x_val > 0.0f) ? 1.0f : -1.0f;
                    y_val = 0.0f;
                }
                
                y_temp_acc[row][batch] = y_val;
                x_temp_acc[row][batch] = x_val;
            }
        }
        
        y.copy_(y_temp);
        x.copy_(x_temp);
    }
}

bool check_device_multi_row_shared_memory_support(int N) {
    int max_threads_per_block;
    return check_multi_row_shared_memory_support(N, &max_threads_per_block);
}

void fused_dynamics_batch_iterations(
    torch::Tensor y,
    torch::Tensor x,
    float delta,
    torch::Tensor p_array,
    float xi,
    float dt,
    torch::Tensor J_indices,
    torch::Tensor J_values,
    torch::Tensor J_crow_ptr,
    int n_iterations
) {
    if (y.is_cuda()) {
        fused_dynamics_batch_iterations_cuda_wrapper(
            y, x, delta, p_array, xi, dt, 
            J_indices, J_values, J_crow_ptr, n_iterations
        );
    } else {
        fused_dynamics_batch_iterations_cpu(
            y, x, delta, p_array, xi, dt, 
            J_indices, J_values, J_crow_ptr, n_iterations
        );
    }
}
'''

class MultiRowSharedMemoryFusedJIT:
    """â­ æ”¯æŒå¤§Nçš„å…±äº«å†…å­˜ç‰ˆæœ¬ï¼šæ¯ä¸ªçº¿ç¨‹å¤„ç†å¤šä¸ªrow"""
    
    _module = None
    _compilation_attempted = False
    
    def __init__(self, J, use_cuda=True, verbose=False):
        self.use_cuda = use_cuda and torch.cuda.is_available()
        self.verbose = verbose
        
        # é¢„å¤„ç†ç¨€ç–çŸ©é˜µ
        if hasattr(J, 'to_sparse_csr'):
            self.J_csr = J.to_sparse_csr()
        else:
            self.J_csr = J.coalesce()
        
        # ç¼–è¯‘CUDAæ‰©å±•
        if self.use_cuda:
            self._compile_cuda_extension()
        
        # PyTorchå›é€€
        self.torch_update = self._single_step_update
    
    def _compile_cuda_extension(self):
        if MultiRowSharedMemoryFusedJIT._compilation_attempted:
            return
        
        MultiRowSharedMemoryFusedJIT._compilation_attempted = True
        
        try:
            if self.verbose:
                print("æ­£åœ¨ç¼–è¯‘å¤šè¡Œå…±äº«å†…å­˜CUDAæ‰©å±•...")
            
            MultiRowSharedMemoryFusedJIT._module = load_inline(
                name='multi_row_shared_fused_dynamics_jit',
                cpp_sources=[cpp_source_multi_row],
                cuda_sources=[cuda_source_multi_row_shared] if self.use_cuda else [],
                functions=['fused_dynamics_batch_iterations', 'check_device_multi_row_shared_memory_support'],
                extra_cflags=['-O3', '-std=c++17', '-fopenmp'],
                extra_cuda_cflags=[
                    '-O3', '--std=c++17',
                    '-gencode=arch=compute_70,code=sm_70',
                    '-gencode=arch=compute_75,code=sm_75', 
                    '-gencode=arch=compute_80,code=sm_80',
                    '-gencode=arch=compute_86,code=sm_86',
                    '--use_fast_math',
                    '--extended-lambda'
                ] if self.use_cuda else [],
                verbose=self.verbose
            )
            
            if self.verbose:
                print("âœ… å¤šè¡Œå…±äº«å†…å­˜CUDAæ‰©å±•ç¼–è¯‘å®Œæˆï¼")
                
        except Exception as e:
            if self.verbose:
                print(f"âŒ CUDAç¼–è¯‘å¤±è´¥ï¼Œä½¿ç”¨PyTorchå›é€€: {e}")
            MultiRowSharedMemoryFusedJIT._module = None
    
    def is_multi_row_shared_memory_supported(self, N):
        """æ£€æŸ¥å¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–æ˜¯å¦æ”¯æŒç»™å®šçš„N"""
        if MultiRowSharedMemoryFusedJIT._module is None:
            return False
        try:
            return MultiRowSharedMemoryFusedJIT._module.check_device_multi_row_shared_memory_support(N)
        except:
            return False
    
    def run_iterations(self, y, x, delta, p_array, xi, dt, n_iterations):
        """è¿è¡Œå¤šä¸ªæ—¶é—´æ­¥"""
        
        if MultiRowSharedMemoryFusedJIT._module is not None and y.is_cuda:
            return self._cuda_iterations(y, x, delta, p_array, xi, dt, n_iterations)
        else:
            return self._torch_iterations(y, x, delta, p_array, xi, dt)
    
    def _cuda_iterations(self, y, x, delta, p_array, xi, dt, n_iterations):
        """â­ CUDAç‰ˆæœ¬ï¼šå¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–"""
        # ç¡®ä¿æ•°æ®ç±»å‹å’Œè¿ç»­æ€§
        if y.dtype != torch.float32:
            y = y.float()
        if x.dtype != torch.float32:
            x = x.float()
        if p_array.dtype != torch.float32:
            p_array = p_array.float()
        
        if not y.is_contiguous():
            y = y.contiguous()
        if not x.is_contiguous():
            x = x.contiguous()
        if not p_array.is_contiguous():
            p_array = p_array.contiguous()
        
        # è·å–CSRæ ¼å¼æ•°æ®
        if hasattr(self.J_csr, 'crow_indices'):
            crow_indices = self.J_csr.crow_indices().int().contiguous()
            col_indices = self.J_csr.col_indices().int().contiguous()
            values = self.J_csr.values().float().contiguous()
        else:
            raise NotImplementedError("è¯·ä½¿ç”¨PyTorch 1.13+")
        
        # ç¡®ä¿æ•°æ®åœ¨GPUä¸Š
        if not crow_indices.is_cuda:
            crow_indices = crow_indices.cuda()
        if not col_indices.is_cuda:
            col_indices = col_indices.cuda()
        if not values.is_cuda:
            values = values.cuda()
        if not p_array.is_cuda:
            p_array = p_array.cuda()
        
        # â­ å¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
        MultiRowSharedMemoryFusedJIT._module.fused_dynamics_batch_iterations(
            y, x, float(delta), p_array, float(xi), float(dt),
            col_indices, values, crow_indices, n_iterations
        )
        
        return y, x
    
    def _torch_iterations(self, y, x, delta, p_array, xi, dt):
        """ä¼ ç»ŸPyTorchç‰ˆæœ¬"""
        for i in range(len(p_array)):
            y, x = self.torch_update(y, x, delta, p_array[i].item(), xi, dt)
        return y, x
    
    def _single_step_update(self, y, x, delta, p_i, xi, dt):
        """å•æ­¥æ›´æ–°çš„PyTorchå®ç°"""
        sign_x = torch.sign(x)
        sparse_term = torch.sparse.mm(self.J_csr, sign_x)
        y = y + (-(delta - p_i) * x + xi * sparse_term) * dt
        x = x + dt * y * delta
        
        cond = torch.abs(x) > 1
        x = torch.where(cond, torch.sign(x), x)
        y = torch.where(cond, torch.zeros_like(x), y)
        
        return y, x

def demo_multi_row_shared_memory():
    """æ¼”ç¤ºæ”¯æŒå¤§Nçš„å…±äº«å†…å­˜ç‰ˆæœ¬"""
    print("=== æ”¯æŒå¤§Nçš„å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬ ===")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # â­ æµ‹è¯•å¤šç§Nå€¼ï¼ŒåŒ…æ‹¬>1024çš„æƒ…å†µ
    test_cases = [
        {"N": 512, "batch_size": 1000, "n_iterations": 500},
        {"N": 1024, "batch_size": 500, "n_iterations": 500},
        {"N": 2048, "batch_size": 100, "n_iterations": 200},  # >1024
        {"N": 4096, "batch_size": 50, "n_iterations": 100},   # æ›´å¤§çš„N
    ]
    
    print(f"è®¾å¤‡: {device}")
    
    for test_case in test_cases:
        N = test_case["N"]
        batch_size = test_case["batch_size"]
        n_iterations = test_case["n_iterations"]
        
        print(f"\n--- æµ‹è¯• N={N}, batch_size={batch_size}, iterations={n_iterations} ---")
        print(f"å…±äº«å†…å­˜éœ€æ±‚: {2*N*4}å­—èŠ‚")
        print(f"æ¯ä¸ªçº¿ç¨‹å¤„ç†: {N/1024:.1f} ä¸ªrow")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        nnz = N * 8  # å¹³å‡æ¯è¡Œ8ä¸ªéé›¶å…ƒç´ 
        indices = torch.randint(0, N, (2, nnz), device=device)
        values = torch.randn(nnz, device=device) * 0.1
        J = torch.sparse_coo_tensor(indices, values, (N, N), device=device)
        
        y = torch.randn(N, batch_size, device=device)
        x = torch.randn(N, batch_size, device=device)
        
        delta, xi, dt = 0.1, 0.5, 0.01
        p_array = torch.randn(n_iterations, device=device)
        
        # â­ ä½¿ç”¨å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬
        multi_row_updater = MultiRowSharedMemoryFusedJIT(J, use_cuda=True, verbose=False)
        
        # æ£€æŸ¥å…±äº«å†…å­˜æ”¯æŒ
        if device == 'cuda':
            support = multi_row_updater.is_multi_row_shared_memory_supported(N)
            print(f"å¤šè¡Œå…±äº«å†…å­˜æ”¯æŒ: {'âœ… æ”¯æŒ' if support else 'âŒ ä¸æ”¯æŒ'}")
            
            if support:
                y1, x1 = y.clone(), x.clone()
                
                torch.cuda.synchronize()
                start = torch.cuda.Event(enable_timing=True)
                end = torch.cuda.Event(enable_timing=True)
                start.record()
                
                y1, x1 = multi_row_updater.run_iterations(y1, x1, delta, p_array, xi, dt, n_iterations)
                
                end.record()
                torch.cuda.synchronize()
                elapsed_time = start.elapsed_time(end)
                
                print(f"å¤šè¡Œå…±äº«å†…å­˜è€—æ—¶: {elapsed_time:.2f}ms")
                print(f"å¹³å‡æ¯æ¬¡è¿­ä»£: {elapsed_time/n_iterations:.3f}ms")
                
                # è®¡ç®—ååé‡
                total_ops = N * batch_size * n_iterations
                throughput = total_ops / (elapsed_time / 1000) / 1e6  # MOps/s
                print(f"ååé‡: {throughput:.1f} MOps/s")
            else:
                print("âš ï¸ å…±äº«å†…å­˜ä¸è¶³ï¼Œè·³è¿‡æµ‹è¯•")
        else:
            print("CPUæ¨¡å¼ï¼Œè·³è¿‡å…±äº«å†…å­˜æµ‹è¯•")

def compare_with_traditional(N=2048, batch_size=100, n_iterations=200):
    """ä¸ä¼ ç»Ÿæ–¹æ³•æ¯”è¾ƒæ€§èƒ½"""
    print(f"\n=== æ€§èƒ½å¯¹æ¯” (N={N}) ===")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    if device == 'cpu':
        print("éœ€è¦CUDAè®¾å¤‡è¿›è¡Œæ€§èƒ½å¯¹æ¯”")
        return
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    nnz = N * 8
    indices = torch.randint(0, N, (2, nnz), device=device)
    values = torch.randn(nnz, device=device) * 0.1
    J = torch.sparse_coo_tensor(indices, values, (N, N), device=device)
    
    y = torch.randn(N, batch_size, device=device)
    x = torch.randn(N, batch_size, device=device)
    
    delta, xi, dt = 0.1, 0.5, 0.01
    p_array = torch.randn(n_iterations, device=device)
    
    # æ–¹æ³•1: å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬
    print("\n--- æ–¹æ³•1: å¤šè¡Œå…±äº«å†…å­˜ç‰ˆæœ¬ ---")
    multi_row_updater = MultiRowSharedMemoryFusedJIT(J, use_cuda=True, verbose=True)
    
    if multi_row_updater.is_multi_row_shared_memory_supported(N):
        y1, x1 = y.clone(), x.clone()
        
        torch.cuda.synchronize()
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        start.record()
        
        y1, x1 = multi_row_updater.run_iterations(y1, x1, delta, p_array, xi, dt, n_iterations)
        
        end.record()
        torch.cuda.synchronize()
        shared_time = start.elapsed_time(end)
        
        print(f"å¤šè¡Œå…±äº«å†…å­˜è€—æ—¶: {shared_time:.2f}ms")
        
        # æ–¹æ³•2: ä¼ ç»Ÿæ–¹å¼
        print("\n--- æ–¹æ³•2: ä¼ ç»Ÿæ–¹å¼ ---")
        y2, x2 = y.clone(), x.clone()
        
        start.record()
        
        for i in range(n_iterations):
            # æ¨¡æ‹Ÿä¼ ç»Ÿçš„å•æ­¥æ›´æ–°
            sign_x = torch.sign(x2)
            if hasattr(J, 'to_sparse_csr'):
                J_csr = J.to_sparse_csr()
            else:
                J_csr = J.coalesce()
            sparse_term = torch.sparse.mm(J_csr, sign_x)
            y2 = y2 + (-(delta - p_array[i].item()) * x2 + xi * sparse_term) * dt
            x2 = x2 + dt * y2 * delta
            
            cond = torch.abs(x2) > 1
            x2 = torch.where(cond, torch.sign(x2), x2)
            y2 = torch.where(cond, torch.zeros_like(x2), y2)
        
        end.record()
        torch.cuda.synchronize()
        traditional_time = start.elapsed_time(end)
        
        print(f"ä¼ ç»Ÿæ–¹å¼è€—æ—¶: {traditional_time:.2f}ms")
        
        # æ€§èƒ½åˆ†æ
        speedup = traditional_time / shared_time
        print(f"\nğŸš€ å¤šè¡Œå…±äº«å†…å­˜åŠ é€Ÿæ¯”: {speedup:.2f}x")
        print(f"èŠ‚çœæ—¶é—´: {traditional_time - shared_time:.2f}ms ({(1-shared_time/traditional_time)*100:.1f}%)")
        
        # éªŒè¯æ•°å€¼ä¸€è‡´æ€§
        y_diff = torch.max(torch.abs(y1 - y2)).item()
        x_diff = torch.max(torch.abs(x1 - x2)).item()
        print(f"\næ•°å€¼å·®å¼‚: y={y_diff:.2e}, x={x_diff:.2e}")
        
        if y_diff < 1e-4 and x_diff < 1e-4:
            print("âœ… æ•°å€¼éªŒè¯é€šè¿‡!")
        else:
            print("âš ï¸  æ•°å€¼æœ‰è½»å¾®å·®å¼‚ï¼ˆåœ¨GPUå¹¶è¡Œè®¡ç®—ä¸­æ˜¯æ­£å¸¸çš„ï¼‰")
    else:
        print("âŒ ä¸æ”¯æŒå¤šè¡Œå…±äº«å†…å­˜ä¼˜åŒ–")

if __name__ == "__main__":
    demo_multi_row_shared_memory()
    compare_with_traditional()
